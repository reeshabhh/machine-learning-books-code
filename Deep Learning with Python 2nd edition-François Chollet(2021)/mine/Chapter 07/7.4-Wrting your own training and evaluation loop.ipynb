{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389610c1-9f7e-4b34-8d22-3b3f896d7b0f",
   "metadata": {},
   "source": [
    "# 7.4.1 Training vs Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3074d9d-ca0b-4773-b6c1-ff009f74d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\reeshabh.choudhary\\\\OneDrive - xpdnp\\\\Coding\\\\ML\\\\Books\\\\Deep Learning with Python 2nd edition-FranÃ§ois Chollet(2021)\\\\mine\\\\Chapter 7'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fae64a8-83f8-4837-8886-80a0c8b4bf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\reeshabh.choudhary\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84b1ba6b-731a-425c-b548-013a42b173ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tracking_metric = keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372a93a3-1de9-4f65-a025-f5d602850fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradients(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59303b-7389-41a6-b23f-24fa68ed250a",
   "metadata": {},
   "source": [
    "# 7.4.2 Low level usages of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fafeff-cb99-4bc3-889c-0fb361b5606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\reeshabh.choudhary\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:585: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776fa517-5c1a-4ea1-bf6a-8eb3792d759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "\n",
    "metrics.update_state(targets, predictions)\n",
    "\n",
    "current_result = metrics.result()\n",
    "\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726c5941-4636-4d0e-be2d-e3736dc255de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f5c2c-6de4-409f-8973-a4eb132fcc11",
   "metadata": {},
   "source": [
    "# 7.4.3-A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14889a73-2fc6-4686-971d-dbd352ce5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28, ))\n",
    "    features = keras.layers.Dense(512, activation='relu')(inputs)\n",
    "    features = keras.layers.Dropout(0.5)(features)\n",
    "    outputs = keras.layers.Dense(10, activation='softmax')(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f47300fa-1933-4a25-a21c-5898e6efc7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbea4c9e-1809-4fe1-9040-f7361d717797",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape((60000, 28 * 28)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cab32244-ab64-4f7c-bb94-c0b2ac9a4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6270e40-a323-42a9-a42a-1d7395c5c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abc03394-4fc2-4358-9f55-0ec2526d5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75e6760b-6e6d-4d5f-83d4-c860079d3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b50ba29b-8250-49d0-bbf4-edc27993b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29152404-8665-490c-a615-d2d8b03cadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0825dc48-2267-46d3-9859-33380b47ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking = keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e817cc4a-a85e-47bf-aef4-57a3d9bf6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metrics.name] = metrics.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a46b76e9-f304-4ef9-893d-9f70e52b848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec37b8c-7cf8-4e38-9c83-507cbef2fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images, train_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "942b9ac1-ad5c-4f1e-9eea-4ad3884549ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4d0f0ff-8e24-4415-ade6-bde2de0dbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ce6d65a-b8e8-472e-a331-241b122b2dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 784), found shape=(32, 2, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m reset_metrics()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m training_dataset:\n\u001b[1;32m----> 4\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults at the end of epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m logs\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(inputs, targets):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m----> 3\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(targets, predictions)\n\u001b[0;32m      5\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:298\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 298\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 784), found shape=(32, 2, 784)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b00958b-004d-439b-a4a0-1554b447ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e38b76d6-2c83-4ade-8598-35fcdf3f17a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_tracking_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((val_images, val_labels))\n\u001b[0;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m, in \u001b[0;36mreset_metrics\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m      3\u001b[0m     metric\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mloss_tracking_metric\u001b[49m\u001b[38;5;241m.\u001b[39mreset_state()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_tracking_metric' is not defined"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d9ca471-a45f-43ea-a5e0-466111a528f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_tracking_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[1;32m----> 2\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation results:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m logs\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m, in \u001b[0;36mtest_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m      7\u001b[0m metric\u001b[38;5;241m.\u001b[39mupdate_state(targets, predictions)\n\u001b[0;32m      8\u001b[0m logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m metric\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss_tracking_metric\u001b[49m\u001b[38;5;241m.\u001b[39mupdate_state(loss)\n\u001b[0;32m     10\u001b[0m logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loss_tracking_metric\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_tracking_metric' is not defined"
     ]
    }
   ],
   "source": [
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print('Evaluation results:')\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56523960-9650-48f9-a2c8-643850ad09bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c135ff-9415-4684-bc31-1cff5ccb0588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7ba57-1907-48ae-9a6f-32fe2f2b6957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
