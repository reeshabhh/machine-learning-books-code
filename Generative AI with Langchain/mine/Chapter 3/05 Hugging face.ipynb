{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd24a9ac-d809-4b67-b102-a56dbda400e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reesh\\python_environments\\langchain_ai_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850caea3-d084-4a5c-9dff-95b7ebeb3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_most_popular(task: str):\n",
    "    for rank, model in enumerate(list_models(filter=task, sort=\"downloads\", direction=-1)):\n",
    "        if rank == 5:\n",
    "            break\n",
    "        print(f\"{model.id}, {model.downloads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf781bf-8001-4d62-aed4-599dad14dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english, 5966207\n",
      "\n",
      "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 4462229\n",
      "\n",
      "smilegate-ai/kor_unsmile, 3213630\n",
      "\n",
      "facebook/bart-large-mnli, 3207905\n",
      "\n",
      "tomh/toxigen_roberta, 1908028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9df569-bb31-409b-b1cd-c4dd3660a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reesh\\python_environments\\langchain_ai_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\reesh\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.7691403031349182}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "sentiment_model = pipeline(\n",
    "task=\"sentiment-analysis\",\n",
    "model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e1cda1-99db-4fef-8d72-8d12f1a3e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reesh\\python_environments\\langchain_ai_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\reesh\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.8635025024414062}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "sentiment_model = pipeline(\n",
    "task=\"sentiment-analysis\",\n",
    "model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b952638-b954-4337-a51f-babd10d13a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.9467711448669434}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"I am so angry and sad, I want to kill myself.\"\"\"\n",
    "sentiment_model = pipeline(\n",
    "task=\"sentiment-analysis\",\n",
    "model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b688d6c-f13e-4b71-a028-af082717754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.775530219078064}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"Very bad\"\"\"\n",
    "sentiment_model = pipeline(task=\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194bbb21-5e67-4806-bf82-04691c2f98c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reesh\\python_environments\\langchain_ai_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\reesh\\.cache\\huggingface\\hub\\models--mrm8488--distilroberta-finetuned-financial-news-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.9029219150543213}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"Very bad\"\"\"\n",
    "sentiment_model = pipeline(task=\"sentiment-analysis\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63234d3d-3ce9-427e-86b6-890d36ce8f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9036b8d-dfa5-4067-80c4-64f911e38711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# OPENAI_API_KEY = \"... \"\n",
    "# I'm omitting all other keys\n",
    "def set_environment():\n",
    "    variable_dict = globals().items()\n",
    "    for key, value in variable_dict:\n",
    "        if \"API\" in key or \"ID\" in key:\n",
    "            os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a5f40d-dfbc-4c12-873b-886b63f54e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A customer's coffee machine arrived broken. \"This heartbreaking display of negligence shattered my dreams,\" writes the customer. \"I was emotionally distraught and inconsolable,\" he adds. \"It was like a war-torn soldier who had fought valiantly on the fields of some espressobattlefield\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "summarizer = HuggingFaceHub(\n",
    "repo_id=\"facebook/bart-large-cnn\",\n",
    "model_kwargs={\"temperature\":0, \"max_length\":180},\n",
    ")\n",
    "def summarize(llm, text) -> str:\n",
    "    return llm(f\"Summarize this: {text}!\")\n",
    "print(summarize(summarizer, customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "027d0451-9887-4fd9-8af6-726f25a63198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_most_popular(task: str):\n",
    "    for rank, model in enumerate(list_models(filter=task, sort=\"downloads\", direction=-1)):\n",
    "        if rank == 5:\n",
    "            break\n",
    "        print(f\"{rank} -> {model.id}, {model.downloads}\\n\")\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bdaf452-0613-42b0-9168-c6956cfa261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 25755638\n",
      "\n",
      "1 -> distilbert/distilbert-base-uncased-finetuned-sst-2-english, 8468358\n",
      "\n",
      "2 -> smilegate-ai/kor_unsmile, 4217553\n",
      "\n",
      "3 -> cardiffnlp/twitter-roberta-base-sentiment-latest, 3924696\n",
      "\n",
      "4 -> facebook/bart-large-mnli, 2439012\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "171e04a8-df87-41bf-ae08-31fb87db8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> GroNLP/hateBERT, 19112\n",
      "\n",
      "1 -> Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city, 18841\n",
      "\n",
      "2 -> patrickquick/BERTicelli, 2968\n",
      "\n",
      "3 -> unhcr/hatespeech-detection, 1265\n",
      "\n",
      "4 -> gsgoncalves/distilbert-base-uncased-race, 833\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"text classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c76a2e6-dcf3-4ec3-b188-45d481db5681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> KipperDev/bart_summarizer_model, 88\n",
      "\n",
      "1 -> KipperDev/t5_summarizer_model, 30\n",
      "\n",
      "2 -> whaleloops/longt5-tglobal-large-16384-pubmed-10k_steps, 2\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"text summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f101381d-0cd4-477a-9bc6-8dfebec384ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"text-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cfa92f4-80c5-4ce9-90e9-03b9f873b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> google-t5/t5-base, 5588487\n",
      "\n",
      "1 -> google-t5/t5-small, 3952754\n",
      "\n",
      "2 -> facebook/bart-large-cnn, 3777557\n",
      "\n",
      "3 -> google-t5/t5-large, 590884\n",
      "\n",
      "4 -> mrm8488/bert2bert_shared-spanish-finetuned-summarization, 568083\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "list_most_popular('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "263c51a1-365c-4f8e-ba6b-430a66dde862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zusammenfassend: Ich schreibe, um mein Herz über die unglückliche Erfahrung zu schütteln, die ich vor kurzem mit einer Ihrer Kaffeemaschinen hatte, die kaputt gekommen ist. Ich entpackte die Schachtel, in der meine heiß erwartete Kaffeemaschine steckte, aber was ich innerhalb entdeckte, zerstörte nicht nur meinen Geist, sondern auch jeden Anschein von Vertrauen, den ich in Ihre Marke\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "summarizer = HuggingFaceHub(\n",
    "repo_id=\"google-t5/t5-base\",\n",
    "model_kwargs={\"temperature\":0, \"max_length\":180},\n",
    ")\n",
    "def summarize(llm, text) -> str:\n",
    "    return llm(f\"Summarize this: {text}!\")\n",
    "print(summarize(summarizer, customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6effcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
