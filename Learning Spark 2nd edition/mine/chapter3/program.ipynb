{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooke', 22.5), ('Denny', 31.0), ('Jules', 30.0), ('TD', 35.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Python\n",
    "# Create an RDD of tuples (name, age)\n",
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "                            (\"TD\", 35), (\"Brooke\", 25)])\n",
    "# Use map and reduceByKey transformations with their lambda\n",
    "# expressions to aggregate and then compute average\n",
    "agesRDD = (dataRDD\n",
    "            .map(lambda x: (x[0], (x[1], 1)))\n",
    "            .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "            .map(lambda x: (x[0], x[1][0]/x[1][1])))\n",
    "agesRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "# Create a DataFrame using SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"AuthorsAges\")\n",
    "    .getOrCreate())\n",
    "# sc = spark.sparkContext\n",
    "# Create a DataFrame\n",
    "data_df = spark.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "     (\"TD\", 35), (\"Brooke\", 25)], [\"name\", \"age\"])\n",
    "# Group the same names together, aggregate their ages, and compute an average\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg(\"age\"))\n",
    "# Show the results of the final execution\n",
    "avg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.session.SparkSession at 0x231c354ff70>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = [SparkSession\n",
    "    .builder\n",
    "    .appName(\"AuthorsAges\")\n",
    "    .getOrCreate()]\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Legion:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>My App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x231c354ff70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"AuthorsAges\")\n",
    "    .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Legion:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>My App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x231c354ff70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AuthorsAges\")\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 2,\n",
    "c = (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(int, tuple, int)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a), type(b), type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyspark.sql.session.SparkSession at 0x231c354ff70>,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"AuthorsAges\")\n",
    "    .getOrCreate(),)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Legion:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>My App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x231c354ff70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"AuthorsAges\")\n",
    "    .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = 2,3,4,\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = (2,3,4,\n",
    "5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Conclusion - While creating the spark object we are using parenthesis (\"()\") because we are initializing it in multiline. If we do not put comma after something even if it is in parenthesis (\"()\") python will not treat it as a tuple instead it will treat it like the type of object inside the parenthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to define a schema\n",
    "Spark allows you to define a schema in two ways. One is to define it programmati‐\r\n",
    "cally, and the other is to employ a Data Definition Language (DDL) string, which is\r\n",
    "much simpler and easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Programmatically defining a schema\n",
    "\n",
    "# In Python\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    "    StructField(\"title\", StringType(), False),\n",
    "    StructField(\"pages\", IntegerType(), False)])\n",
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining schema using DDL\n",
    "\n",
    "# In Python\n",
    "from pyspark.sql import SparkSession\n",
    "# Define schema for our data using DDL\n",
    "schema = \"Id INT, First STRING, Last STRING, Url STRING,\\\n",
    "    Published STRING, Hits INT, Campaigns ARRAY<STRING>\"\n",
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our static data\n",
    "data = [\n",
    "    [1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\",\n",
    "        \"LinkedIn\"]],\n",
    "    [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\",\n",
    "        \"LinkedIn\"]],\n",
    "    [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\",\n",
    "        \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568,\n",
    "        [\"twitter\", \"FB\"]],\n",
    "    [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\",\n",
    "        \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568,\n",
    "        [\"twitter\", \"LinkedIn\"]]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "# Create a SparkSession\n",
    "    spark = (SparkSession\n",
    "            .builder\n",
    "            .appName(\"Example-3_6\")\n",
    "            .getOrCreate())\n",
    "    # Create a DataFrame using the schema defined above\n",
    "    blogs_df = spark.createDataFrame(data, schema)\n",
    "    # Show the DataFrame; it should reflect our table above\n",
    "    blogs_df.show()\n",
    "    # Print the schema used by Spark to process the DataFrame\n",
    "    print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the explicit schema specified.\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)])\n",
    "spark.createDataFrame([('Alice', 1)], schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the schema in DDL formatted string.\n",
    "\n",
    "spark.createDataFrame([('Alice', 1)], \"name: string, age: int\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.types as T                   \n",
    "\n",
    "# here is the traditional way to define a shema in PySpark\n",
    "schema = T.StructType([\n",
    "  T.StructField(\"col1\", T.StringType(), True),\n",
    "  T.StructField(\"col2\", T.IntegerType(), True),\n",
    "  T.StructField(\"col3\", T.TimestampType(), True)\n",
    "])\n",
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.types as T                   \n",
    "\n",
    "# and here is the way using the helper function out of types\n",
    "ddl_schema_string = \"col1 string, col2 integer, col3 timestamp\"\n",
    "ddl_schema = T._parse_datatype_string(ddl_schema_string)\n",
    "type(ddl_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('col1', StringType(), True), StructField('col2', IntegerType(), True), StructField('col3', TimestampType(), True)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T._parse_datatype_string(ddl_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Id', IntegerType(), True), StructField('First', StringType(), True), StructField('Last', StringType(), True), StructField('Url', StringType(), True), StructField('Published', StringType(), True), StructField('Hits', IntegerType(), True), StructField('Campaigns', ArrayType(StringType(), True), True)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want to use this schema elsewhere in your code, simply execute\r",
    "# blogs_df.schema and it will return the schema definition:\n",
    "blogs_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Show columns and expressions\n",
    "blogs_df.select(expr(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(col(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(expr(\"Hits * 2\")).show(2)\n",
    "# show heavy hitters\n",
    "blogs_df.withColumn(\"Big Hitters\", (expr(\"Hits > 10000\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogsDF = blogs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Use an expression to compute big hitters for blogs\n",
    "# // This adds a new column, Big Hitters, based on the conditional expression\n",
    "blogsDF.withColumn(\"Big Hitters\", (expr(\"Hits > 10000\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    AuthorsId|\n",
      "+-------------+\n",
      "|  JulesDamji1|\n",
      "| BrookeWenig2|\n",
      "|    DennyLee3|\n",
      "|TathagataDas4|\n",
      "+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Concatenate three columns, create a new column, and show the\n",
    "# // newly created concatenated column\n",
    "(blogsDF\n",
    ".withColumn(\"AuthorsId\", (concat(expr(\"First\"), expr(\"Last\"), expr(\"Id\"))))\n",
    ".select(col(\"AuthorsId\"))\n",
    ".show(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // These statements return the same value, showing that\n",
    "# // expr is the same as a col method call\n",
    "blogsDF.select(expr(\"Hits\")).show(2)\n",
    "blogsDF.select(col(\"Hits\")).show(2)\n",
    "blogsDF.select(\"Hits\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# // Sort by column \"Id\" in descending order\n",
    "blogsDF.sort(col(\"Id\").desc()).show()\n",
    "blogsDF.sort(expr(\"Id\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Reynold',\n",
       " <Row(6, 'Reynold', 'Xin', 'https://tinyurl.6', 255568, '3/2/2015', ['twitter', 'LinkedIn'])>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Python\n",
    "from pyspark.sql import Row\n",
    "blog_row = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\",\n",
    "    [\"twitter\", \"LinkedIn\"])\n",
    "# access using index for individual items\n",
    "blog_row[1], blog_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Authors|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "rows = [Row(\"Matei Zaharia\", \"CA\"), Row(\"Reynold Xin\", \"CA\")]\n",
    "authors_df = spark.createDataFrame(rows, [\"Authors\", \"State\"])\n",
    "authors_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row('Matei Zaharia', 'CA')>, <Row('Reynold Xin', 'CA')>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row('Matei Zaharia', 'CA')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matei Zaharia'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "df = spark.range(0, 10000, 1, 8) # this code will create a DataFrame of 10,000 integers distributed over eight parti‐\n",
    "# tions in memory \n",
    "print(df.rdd.getNumPartitions()) # it should print 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common DataFrame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python, define a schema\n",
    "from pyspark.sql.types import *\n",
    "# Programmatic way to define a schema\n",
    "fire_schema = StructType(\n",
    "    [StructField('CallNumber', IntegerType(), True),\n",
    "    StructField('UnitID', StringType(), True),\n",
    "    StructField('IncidentNumber', IntegerType(), True),\n",
    "    StructField('CallType', StringType(), True),\n",
    "    StructField('CallDate', StringType(), True),\n",
    "    StructField('WatchDate', StringType(), True),\n",
    "    StructField('CallFinalDisposition', StringType(), True),\n",
    "    StructField('AvailableDtTm', StringType(), True),\n",
    "    StructField('Address', StringType(), True),\n",
    "    StructField('City', StringType(), True),\n",
    "    StructField('Zipcode', IntegerType(), True),\n",
    "    StructField('Battalion', StringType(), True),\n",
    "    StructField('StationArea', StringType(), True),\n",
    "    StructField('Box', StringType(), True),\n",
    "    StructField('OriginalPriority', StringType(), True),\n",
    "    StructField('Priority', StringType(), True),\n",
    "    StructField('FinalPriority', IntegerType(), True),\n",
    "    StructField('ALSUnit', BooleanType(), True),\n",
    "    StructField('CallTypeGroup', StringType(), True),\n",
    "    StructField('NumAlarms', IntegerType(), True),\n",
    "    StructField('UnitType', StringType(), True),\n",
    "    StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "    StructField('FirePreventionDistrict', StringType(), True),\n",
    "    StructField('SupervisorDistrict', StringType(), True),\n",
    "    StructField('Neighborhood', StringType(), True),\n",
    "    StructField('Location', StringType(), True),\n",
    "    StructField('RowID', StringType(), True),\n",
    "    StructField('Delay', FloatType(), True)]\n",
    ")\n",
    "\n",
    "# Use the DataFrameReader interface to read a CSV file\n",
    "sf_fire_file = \"sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(CallNumber=20110016, UnitID='T13', IncidentNumber=2003235, CallType='Structure Fire', CallDate='01/11/2002', WatchDate='01/10/2002', CallFinalDisposition='Other', AvailableDtTm='01/11/2002 01:51:44 AM', Address='2000 Block of CALIFORNIA ST', City='SF', Zipcode=94109, Battalion='B04', StationArea='38', Box='3362', OriginalPriority='3', Priority='3', FinalPriority=3, ALSUnit=False, CallTypeGroup=None, NumAlarms=1, UnitType='TRUCK', UnitSequenceInCallDispatch=2, FirePreventionDistrict='4', SupervisorDistrict='5', Neighborhood='Pacific Heights', Location='(37.7895840679362, -122.428071912459)', RowID='020110016-T13', Delay=2.950000047683716)]\n"
     ]
    }
   ],
   "source": [
    "print(fire_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate  |WatchDate |CallFinalDisposition|AvailableDtTm         |Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood         |Location                             |RowID        |Delay    |\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |01/11/2002|01/10/2002|Other               |01/11/2002 01:51:44 AM|2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |NULL         |1        |TRUCK   |2                         |4                     |5                 |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|2.95     |\n",
      "|20110022  |M17   |2003241       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 03:01:18 AM|0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |NULL         |1        |MEDIC   |1                         |10                    |10                |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|4.7      |\n",
      "|20110023  |M41   |2003242       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 02:39:50 AM|MARKET ST/MCALLISTER ST    |SF  |94102  |B03      |01         |1455|3               |3       |3            |true   |NULL         |1        |MEDIC   |2                         |3                     |6                 |Tenderloin           |(37.7811772186856, -122.411699931232)|020110023-M41|2.4333334|\n",
      "|20110032  |E11   |2003250       |Vehicle Fire    |01/11/2002|01/10/2002|Other               |01/11/2002 04:16:46 AM|APPLETON AV/MISSION ST     |SF  |94110  |B06      |32         |5626|3               |3       |3            |false  |NULL         |1        |ENGINE  |1                         |6                     |9                 |Bernal Heights       |(37.7388432849018, -122.423948785199)|020110032-E11|1.5      |\n",
      "|20110043  |B04   |2003259       |Alarms          |01/11/2002|01/10/2002|Other               |01/11/2002 06:01:58 AM|1400 Block of SUTTER ST    |SF  |94109  |B04      |03         |3223|3               |3       |3            |false  |NULL         |1        |CHIEF   |2                         |4                     |2                 |Western Addition     |(37.7872890372638, -122.424236212664)|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(fire_df.show(5, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CallNumber=20110016, UnitID='T13', IncidentNumber=2003235, CallType='Structure Fire', CallDate='01/11/2002', WatchDate='01/10/2002', CallFinalDisposition='Other', AvailableDtTm='01/11/2002 01:51:44 AM', Address='2000 Block of CALIFORNIA ST', City='SF', Zipcode=94109, Battalion='B04', StationArea='38', Box='3362', OriginalPriority='3', Priority='3', FinalPriority=3, ALSUnit=False, CallTypeGroup=None, NumAlarms=1, UnitType='TRUCK', UnitSequenceInCallDispatch=2, FirePreventionDistrict='4', SupervisorDistrict='5', Neighborhood='Pacific Heights', Location='(37.7895840679362, -122.428071912459)', RowID='020110016-T13', Delay=2.950000047683716)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13| 2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|  4.7|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate  |WatchDate |CallFinalDisposition|AvailableDtTm         |Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood         |Location                             |RowID        |Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |01/11/2002|01/10/2002|Other               |01/11/2002 01:51:44 AM|2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |NULL         |1        |TRUCK   |2                         |4                     |5                 |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|2.95 |\n",
      "|20110022  |M17   |2003241       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 03:01:18 AM|0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |NULL         |1        |MEDIC   |1                         |10                    |10                |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|4.7  |\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.output_area pre {\n",
       "    white-space: pre;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "div.output_area pre {\n",
    "    white-space: pre;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13| 2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|  4.7|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(2, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate  |WatchDate |CallFinalDisposition|AvailableDtTm         |Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood         |Location                             |RowID        |Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |01/11/2002|01/10/2002|Other               |01/11/2002 01:51:44 AM|2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |NULL         |1        |TRUCK   |2                         |4                     |5                 |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|2.95 |\n",
      "|20110022  |M17   |2003241       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 03:01:18 AM|0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |NULL         |1        |MEDIC   |1                         |10                    |10                |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|4.7  |\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java 17.0.9 2023-10-17 LTS\n",
      "Java(TM) SE Runtime Environment (build 17.0.9+11-LTS-201)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 17.0.9+11-LTS-201, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python to save as a Parquet file\n",
    "parquet_path = \"written_data/parquet_file_1\"\n",
    "fire_df.write.mode(\"overwrite\").format(\"parquet\").save(parquet_path) # parquet file will be written inside written_data/parquet_file_1 folder\n",
    "\n",
    "fire_df.write.mode(\"overwrite\").format(\"parquet\").save(\"written_data/parquet_file_2\") # parquet file will be written inside written_data/parquet_file_2 folder\n",
    "\n",
    "# Another way\n",
    "fire_df.write.mode(\"overwrite\").parquet(\"written_data/parquet_file_3\") # parquet file will be written inside written_data/parquet_file_3 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python to save as a csv file\n",
    "csv_path = \"written_data/csv_file_1\"\n",
    "fire_df.write.mode(\"overwrite\").format(\"csv\").save(csv_path) # csv file will be written inside written_data/csv_file_1 folder\n",
    "\n",
    "fire_df.write.mode(\"overwrite\").format(\"csv\").save(\"written_data/csv_file_2\") # csv file will be written inside written_data/csv_file_2 folder\n",
    "\n",
    "# Another way\n",
    "fire_df.write.mode(\"overwrite\").csv(\"written_data/csv_file_3\") # csv file will be written inside written_data/csv_file_3 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python Writing to SQL table named parquet_table\n",
    "# \n",
    "# parquet_table = parquet_table # name of the table\n",
    "# fire_df.write.format(\"parquet\").saveAsTable(parquet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "few_fire_df = (fire_df\n",
    ".select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    ".where(col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python, return number of distinct types of calls using countDistinct()\n",
    "from pyspark.sql.functions import *\n",
    "(fire_df.select(\"CallType\")\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".agg(countDistinct(\"CallType\").alias(\"DistinctCallTypes\"))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|CallType                           |\n",
      "+-----------------------------------+\n",
      "|Elevator / Escalator Rescue        |\n",
      "|Marine Fire                        |\n",
      "|Aircraft Emergency                 |\n",
      "|Confined Space / Structure Collapse|\n",
      "|Administrative                     |\n",
      "|Alarms                             |\n",
      "|Odor (Strange / Unknown)           |\n",
      "|Citizen Assist / Service Call      |\n",
      "|HazMat                             |\n",
      "|Watercraft in Distress             |\n",
      "+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python, filter for only distinct non-null CallTypes from all the rows\n",
    "(fire_df\n",
    ".select(\"CallType\")\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".distinct()\n",
    ".show(10, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming, adding, and dropping columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(new_fire_df\n",
    ".select(\"ResponseDelayedinMins\")\n",
    ".where(col(\"ResponseDelayedinMins\") > 5)\n",
    ".show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python\n",
    "fire_ts_df = (new_fire_df\n",
    "    .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    "    .drop(\"CallDate\")\n",
    "    .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    "    .drop(\"WatchDate\")\n",
    "    .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "    .drop(\"AvailableDtTm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the converted columns\n",
    "(fire_ts_df\n",
    "    .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    "    .show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select(year('IncidentDate'))\n",
    "    .distinct()\n",
    "    .orderBy(year('IncidentDate'))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- ResponseDelayedinMins: float (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- OnWatchDate: timestamp (nullable = true)\n",
      " |-- AvailableDtTS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    ".select(col(\"CallType\"), col(\"CallType\"))# , count(col(\"CallType\")))\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".groupBy(\"CallType\")\n",
    ".count()\n",
    ".orderBy(\"count\", ascending=False)\n",
    ".show(n=10, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fire_ts_df\n",
    ".createOrReplaceTempView(\"fire_ts_df_tbl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallNumber', 'UnitID', 'IncidentNumber', 'CallType', 'CallFinalDisposition', 'Address', 'City', 'Zipcode', 'Battalion', 'StationArea', 'Box', 'OriginalPriority', 'Priority', 'FinalPriority', 'ALSUnit', 'CallTypeGroup', 'NumAlarms', 'UnitType', 'UnitSequenceInCallDispatch', 'FirePreventionDistrict', 'SupervisorDistrict', 'Neighborhood', 'Location', 'RowID', 'ResponseDelayedinMins', 'IncidentDate', 'OnWatchDate', 'AvailableDtTS']\n"
     ]
    }
   ],
   "source": [
    "print(fire_ts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------------------+-------------------+-------------------+-------------------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|CallFinalDisposition|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|ResponseDelayedinMins|       IncidentDate|        OnWatchDate|      AvailableDtTS|\n",
      "+----------+------+--------------+----------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------------------+-------------------+-------------------+-------------------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|               Other|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|                 2.95|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|  20110022|   M17|       2003241|Medical Incident|               Other|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|                  4.7|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|  20110023|   M41|       2003242|Medical Incident|               Other|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|            2.4333334|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|               Other|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|                  1.5|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|  20110043|   B04|       2003259|          Alarms|               Other|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|            3.4833333|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "|  20110072|   T08|       2003279|  Structure Fire|               Other|  BEALE ST/FOLSOM ST|  SF|  94105|      B03|         35|2122|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     3|                 6|Financial Distric...|(37.7886866619654...|020110072-T08|                 1.75|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 08:03:26|\n",
      "|  20110125|   E33|       2003301|          Alarms|               Other|0 Block of FARALL...|  SF|  94112|      B09|         33|8324|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         2|                     9|                11|Oceanview/Merced/...|(37.7140353531157...|020110125-E33|            2.7166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 09:46:44|\n",
      "|  20110130|   E36|       2003304|          Alarms|               Other|600 Block of POLK ST|  SF|  94102|      B02|         03|3114|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     2|                 6|          Tenderloin|(37.7826266328595...|020110130-E36|            1.7833333|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 09:58:53|\n",
      "|  20110197|   E05|       2003343|Medical Incident|               Other|1500 Block of WEB...|  SF|  94115|      B04|         05|3513|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     4|                 5|           Japantown|(37.784958590666,...|020110197-E05|            1.5166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 12:06:57|\n",
      "|  20110215|   E06|       2003348|Medical Incident|               Other|DIAMOND ST/MARKET ST|  SF|  94114|      B05|         06|5415|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     5|                 8| Castro/Upper Market|(37.7618954753708...|020110215-E06|            2.7666667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 13:08:40|\n",
      "+----------+------+--------------+----------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql\n",
    "(\"SELECT * FROM FIRE_TS_DF_TBL limit 10\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|YEAR|  CNT|\n",
      "+----+-----+\n",
      "|2017|12135|\n",
      "|2016|11609|\n",
      "|2015|11458|\n",
      "|2014|10775|\n",
      "|2018|10136|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql('SELECT YEAR(IncidentDate) AS YEAR, count(IncidentNumber) AS CNT FROM FIRE_TS_DF_TBL GROUP BY YEAR(IncidentDate) ORDER BY CNT DESC limit 5')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|      YEAR|CNT|\n",
      "+----------+---+\n",
      "|2000-04-12|  2|\n",
      "|2001-11-25|  5|\n",
      "|2006-10-15|  7|\n",
      "|2001-08-26|  7|\n",
      "|2007-02-07|  8|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql('SELECT TRIM(TO_DATE(IncidentDate, \"YYYY\")) YEAR, count(IncidentNumber) CNT FROM FIRE_TS_DF_TBL GROUP BY TRIM(TO_DATE(IncidentDate, \"YYYY\")) ORDER BY CNT LIMIT 5')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|IncidentNumber|\n",
      "+--------------+\n",
      "|       2004619|\n",
      "|       2006963|\n",
      "|       2007184|\n",
      "|       2007484|\n",
      "|       2008576|\n",
      "|       2014509|\n",
      "|       2019031|\n",
      "|       2026677|\n",
      "|       2026940|\n",
      "|       2027275|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql\n",
    "(\"SELECT distinct(IncidentNumber) FROM FIRE_TS_DF_TBL limit 10\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|CALLNUMBER|\n",
      "+----------+\n",
      "|  20140023|\n",
      "|  20210263|\n",
      "|  20380045|\n",
      "|  20570327|\n",
      "|  20860368|\n",
      "|  20900223|\n",
      "|  21240138|\n",
      "|  21250076|\n",
      "|  21390387|\n",
      "|  21410339|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql\n",
    "(\"SELECT distinct(CALLNUMBER) FROM FIRE_TS_DF_TBL limit 10\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupBy(“col1”).agg({“col2”: “avg”}).orderBy(“col1”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------+\n",
      "|CallType                     |count |\n",
      "+-----------------------------+------+\n",
      "|Medical Incident             |113794|\n",
      "|Structure Fire               |23319 |\n",
      "|Alarms                       |19406 |\n",
      "|Traffic Collision            |7013  |\n",
      "|Citizen Assist / Service Call|2524  |\n",
      "+-----------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    ".select(\"CallType\")\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".groupBy(\"CallType\")\n",
    ".count()\n",
    ".orderBy(\"count\", ascending=False)\n",
    ".show(n=5, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------+\n",
      "|CallType                     |count |\n",
      "+-----------------------------+------+\n",
      "|Medical Incident             |113794|\n",
      "|Structure Fire               |23319 |\n",
      "|Alarms                       |19406 |\n",
      "|Traffic Collision            |7013  |\n",
      "|Citizen Assist / Service Call|2524  |\n",
      "+-----------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    # .select(\"CallType\")\n",
    "    .where(col(\"CallType\").isNotNull())\n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    ".show(n=5, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|year(IncidentDate)|count|\n",
      "+------------------+-----+\n",
      "|              2003| 8499|\n",
      "|              2007| 8255|\n",
      "|              2018|10136|\n",
      "|              2015|11458|\n",
      "+------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .groupBy(year(\"IncidentDate\"))\n",
    "    .count()\n",
    ").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+\n",
      "|Year|            CallType|count|\n",
      "+----+--------------------+-----+\n",
      "|2018|Citizen Assist / ...|  113|\n",
      "|2018|       Assist Police|    1|\n",
      "|2018|          Fuel Spill|   10|\n",
      "|2018|    Medical Incident| 7004|\n",
      "+----+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .groupBy(year(\"IncidentDate\").alias(\"Year\"), \"CallType\")\n",
    "    .count().alias(\"Count of incidents\")\n",
    "     .orderBy(\"year\", ascending = False)\n",
    ").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----+\n",
      "|Year|       incidentdate|count|\n",
      "+----+-------------------+-----+\n",
      "|2017|2017-09-01 00:00:00|   75|\n",
      "|2017|2017-09-02 00:00:00|   66|\n",
      "|2018|2018-01-01 00:00:00|   58|\n",
      "+----+-------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"IncidentDate\", \"CallType\")\n",
    " .groupBy(year(\"IncidentDate\").alias(\"Year\"), \"incidentdate\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- ResponseDelayedinMins: float (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- OnWatchDate: timestamp (nullable = true)\n",
      " |-- AvailableDtTS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupBy(“col1”).agg({“col2”: “avg”}).orderBy(“col1”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(NumAlarms)|\n",
      "+------------------+\n",
      "|1.0049858525009128|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .select(avg(\"NumAlarms\"))\n",
    "    # .avg()\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(NumAlarms)|\n",
      "+----------------+\n",
      "|          175296|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .select(count(\"NumAlarms\"))\n",
    "    # .avg()\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|NumAlarms| count|\n",
      "+---------+------+\n",
      "|        1|174718|\n",
      "|        3|   121|\n",
      "|        5|    17|\n",
      "+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .where(col(\"NumAlarms\").isNotNull())\n",
    "    .groupBy(\"NumAlarms\")\n",
    "    .count()\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  175296|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .select(count(\"*\"))\n",
    "    # .avg()\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|day(IncidentDate)|count|\n",
      "+-----------------+-----+\n",
      "|               31| 3360|\n",
      "|               28| 5732|\n",
      "|               26| 5491|\n",
      "+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .count()\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|year(IncidentDate)|count|\n",
      "+------------------+-----+\n",
      "|              2017|12135|\n",
      "|              2016|11609|\n",
      "|              2015|11458|\n",
      "+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    ".groupBy(year(\"IncidentDate\"))\n",
    "# .mean()\n",
    " .count()\n",
    ".orderBy(\"count\", ascending=False)\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|day(IncidentDate)|count|\n",
      "+-----------------+-----+\n",
      "|                1| 6233|\n",
      "|                4| 6048|\n",
      "|                5| 5931|\n",
      "+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    ".groupBy(day(\"IncidentDate\"))\n",
    "# .mean()\n",
    " .count()\n",
    ".orderBy(\"count\", ascending=False)\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by date group by call type - see average callnumber on that date of call type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see year wise average number of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG\n",
    "df = spark.sql(\"\"\"SELECT ACCT,AMT,TXN_DT FROM VALUES \n",
    "(101,10.01, DATE'2021-01-01'),\n",
    "(101,102.01, DATE'2021-01-01'),\n",
    "(102,93., DATE'2021-01-01'),\n",
    "(103,913.1, DATE'2021-01-02'),\n",
    "(102,913.1, DATE'2021-01-02'),\n",
    "(101,900.56, DATE'2021-01-03')\n",
    "AS TXN(ACCT,AMT,TXN_DT) \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+\n",
      "|ACCT|  AMT|    TXN_DT|\n",
      "+----+-----+----------+\n",
      "| 101|10.01|2021-01-01|\n",
      "+----+-----+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallNumber', 'UnitID', 'IncidentNumber', 'CallType', 'CallFinalDisposition', 'Address', 'City', 'Zipcode', 'Battalion', 'StationArea', 'Box', 'OriginalPriority', 'Priority', 'FinalPriority', 'ALSUnit', 'CallTypeGroup', 'NumAlarms', 'UnitType', 'UnitSequenceInCallDispatch', 'FirePreventionDistrict', 'SupervisorDistrict', 'Neighborhood', 'Location', 'RowID', 'ResponseDelayedinMins', 'IncidentDate', 'OnWatchDate', 'AvailableDtTS']\n"
     ]
    }
   ],
   "source": [
    "print(fire_ts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|    TXN_DT|  AVG_AMT|\n",
      "+----------+---------+\n",
      "|2021-01-01|68.340000|\n",
      "+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"TXN_DT\").agg(avg(\"AMT\").alias(\"AVG_AMT\")).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|day(IncidentDate)|sum(NumAlarms)|\n",
      "+-----------------+--------------+\n",
      "|               31|          3400|\n",
      "|               28|          5781|\n",
      "|               26|          5529|\n",
      "+-----------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .agg(sum(\"NumAlarms\"))\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|day(IncidentDate)|    avg(NumAlarms)|\n",
      "+-----------------+------------------+\n",
      "|               31|1.0119047619047619|\n",
      "|               28|1.0085484996510816|\n",
      "|               26|1.0069204152249136|\n",
      "+-----------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .agg(avg(\"NumAlarms\"))\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------------+\n",
      "|day(IncidentDate)|count(day(IncidentDate))|\n",
      "+-----------------+------------------------+\n",
      "|               31|                    3360|\n",
      "|               28|                    5732|\n",
      "|               26|                    5491|\n",
      "+-----------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .agg(count(day(\"IncidentDate\")))\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0119047619047619"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3400/3360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|day(IncidentDate)|    avg(NumAlarms)|\n",
      "+-----------------+------------------+\n",
      "|               31|1.0119047619047619|\n",
      "|               28|1.0085484996510816|\n",
      "|               26|1.0069204152249136|\n",
      "+-----------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    (\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .mean(\"NumAlarms\")\n",
    "    )\n",
    ".show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|day(IncidentDate)|    avg(NumAlarms)|\n",
      "+-----------------+------------------+\n",
      "|               31|1.0119047619047619|\n",
      "|               28|1.0085484996510816|\n",
      "|               26|1.0069204152249136|\n",
      "+-----------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    (\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .avg(\"NumAlarms\")\n",
    "    )\n",
    ".show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|day(IncidentDate)|sum(NumAlarms)|\n",
      "+-----------------+--------------+\n",
      "|               31|          3400|\n",
      "|               28|          5781|\n",
      "|               26|          5529|\n",
      "+-----------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    (\n",
    "    fire_ts_df\n",
    "    .groupBy(day(\"IncidentDate\"))\n",
    "    .sum(\"NumAlarms\")\n",
    "    )\n",
    ".show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other common DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(fire_ts_df\n",
    "    .select(F.sum(\"NumAlarms\"), F.avg(\"ResponseDelayedinMins\"),\n",
    "    F.min(\"ResponseDelayedinMins\"), F.max(\"ResponseDelayedinMins\"))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> read the\r\n",
    "API documentation for methods like stat(), describe(), correlation(),\r\n",
    "covariance(), sampleBy(), approxQuantile(), frequentItems(), and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typed Objects, Untyped Objects, and Generic Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "row = Row(350, True, \"Learning Spark 2E\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 is of type :- <class 'int'>\n",
      "True is of type :- <class 'bool'>\n",
      "Learning Spark 2E is of type :- <class 'str'>\n",
      "None is of type :- <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f\"{row[i]} is of type :- {type(row[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   WA| Green| 1779|\n",
      "|   OR|Orange| 1743|\n",
      "|   TX| Green| 1737|\n",
      "|   TX|   Red| 1725|\n",
      "|   CA| Green| 1723|\n",
      "|   CO|Yellow| 1721|\n",
      "|   CA| Brown| 1718|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "+-----+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnm_df = (spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"mnm_dataset.csv\"))\n",
    "count_mnm_df = (mnm_df\n",
    ".select(\"State\", \"Color\", \"Count\")\n",
    ".groupBy(\"State\", \"Color\")\n",
    ".agg(count(\"Count\")\n",
    ".alias(\"Total\"))\n",
    ".orderBy(\"Total\", ascending=False))\n",
    "count_mnm_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['Total DESC NULLS LAST], true\n",
      "+- Aggregate [State#2988, Color#2989], [State#2988, Color#2989, count(Count#2990) AS Total#3002L]\n",
      "   +- Project [State#2988, Color#2989, Count#2990]\n",
      "      +- Relation [State#2988,Color#2989,Count#2990] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "State: string, Color: string, Total: bigint\n",
      "Sort [Total#3002L DESC NULLS LAST], true\n",
      "+- Aggregate [State#2988, Color#2989], [State#2988, Color#2989, count(Count#2990) AS Total#3002L]\n",
      "   +- Project [State#2988, Color#2989, Count#2990]\n",
      "      +- Relation [State#2988,Color#2989,Count#2990] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [Total#3002L DESC NULLS LAST], true\n",
      "+- Aggregate [State#2988, Color#2989], [State#2988, Color#2989, count(Count#2990) AS Total#3002L]\n",
      "   +- Relation [State#2988,Color#2989,Count#2990] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [Total#3002L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(Total#3002L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=2107]\n",
      "      +- HashAggregate(keys=[State#2988, Color#2989], functions=[count(Count#2990)], output=[State#2988, Color#2989, Total#3002L])\n",
      "         +- Exchange hashpartitioning(State#2988, Color#2989, 200), ENSURE_REQUIREMENTS, [plan_id=2104]\n",
      "            +- HashAggregate(keys=[State#2988, Color#2989], functions=[partial_count(Count#2990)], output=[State#2988, Color#2989, count#3016L])\n",
      "               +- FileScan csv [State#2988,Color#2989,Count#2990] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/OneDrive - xpdnp/Coding/Data Science/Books/Learning Spark 2nd..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<State:string,Color:string,Count:int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_mnm_df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
